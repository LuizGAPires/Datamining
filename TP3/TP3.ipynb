{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import darts  # Biblioteca para previsão de séries temporais\n",
    "from darts.utils.statistics import check_seasonality, plot_acf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "\n",
    "custom_params = {\"axes.spines.right\": False, \"axes.spines.top\": False}\n",
    "sns.set_theme(style=\"ticks\", rc=custom_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dia 1 (16/05/2024)\n",
    "#d1_train = pd.read_csv('d1_train.csv')\n",
    "#d1_test_hr = pd.read_csv('d1_teste_hora.csv')\n",
    "#d1_test_local1= pd.read_csv('d1_local_1.csv')\n",
    "#d1_test_local2= pd.read_csv('d1_local_2.csv')\n",
    "#dia 2 (17/05/2024)\n",
    "#d2_train = pd.read_csv('d2_train.csv')\n",
    "#d2_test_hr = pd.read_csv('d2_test_hora.csv')\n",
    "#d2_test_local1= pd.read_csv('d2_local_1.csv')\n",
    "#d2_test_local2= pd.read_csv('d2_local_2.csv')\n",
    "#dia 3 (18/05/2024)\n",
    "#d3_train = pd.read_csv('d3_train.csv')\n",
    "#d3_test_hr = pd.read_csv('d3_test_hora.csv')\n",
    "#d3_test_local1= pd.read_csv('d3_local_1.csv')\n",
    "#d3_test_local2= pd.read_csv('d3_local_2.csv')\n",
    "#dia 4 (19/05/2024)\n",
    "#d4_train = pd.read_csv('d4_train.csv')\n",
    "#d4_test_hr = pd.read_csv('d4_test_hora.csv')\n",
    "#d4_test_local1= pd.read_csv('d4_local_1.csv')\n",
    "#d4_test_local2= pd.read_csv('d4_local_2.csv')\n",
    "#dia 5 (20/05/2024)\n",
    "d5_train = pd.read_csv('d5_train.csv')\n",
    "d5_test_hr = pd.read_csv('d5_test_hora.csv')\n",
    "d5_test_local1= pd.read_csv('d5_local_1.csv')\n",
    "d5_test_local2= pd.read_csv('d5_local_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os `.csv` de treino já foram tratados utilizando SQL para filtrar os ônibus que estão parados na garagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(df):\n",
    "    summ = pd.DataFrame(index = list(df))\n",
    "    summ['type'] = df.dtypes\n",
    "    summ['count'] = df.count()\n",
    "    summ['nunique'] = df.nunique()\n",
    "    summ['%unique'] = summ['nunique'] / len(df) * 100\n",
    "    summ['null'] = df.isnull().sum()\n",
    "    summ['%null'] = summ['null'] / len(df) * 100\n",
    "    summ['min'] = df.min()\n",
    "    summ['max'] = df.max()\n",
    "    return summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(d5_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando o Modelo para latitude e longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder_ordem = LabelEncoder()\n",
    "\n",
    "d5_train['ordem_encoded'] = label_encoder_ordem.fit_transform(d5_train['ordem'])\n",
    "d5_test_hr['ordem_encoded'] = label_encoder_ordem.fit_transform(d5_test_hr['ordem'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'linha',\n",
    "    'datahora',\n",
    "    'ordem_encoded',\n",
    "]\n",
    "\n",
    "target_lat = 'latitude'\n",
    "\n",
    "X = d5_train[features]\n",
    "y_lat = d5_train[target_lat]\n",
    "\n",
    "X_train, X_test, y_train_lat, y_test_lat = train_test_split(X, y_lat, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_lat = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    n_estimators=1000,          \n",
    "    learning_rate=0.05,         \n",
    "    max_depth=5,                \n",
    "    subsample=0.8,              \n",
    "    colsample_bytree=0.8,       \n",
    "    random_state=42,\n",
    "    n_jobs=-1                   \n",
    ")\n",
    "\n",
    "# Treinar o modelo\n",
    "xgb_lat.fit(X_train, y_train_lat,\n",
    "          eval_set=[(X_test, y_test_lat)], verbose=False)\n",
    "\n",
    "# 4. Avaliar o modelo\n",
    "preds_lat = xgb_lat.predict(X_test)\n",
    "rmse_lat = np.sqrt(mean_squared_error(y_test_lat, preds_lat))\n",
    "print(f\"O RMSE para a previsão de Latitude é: {rmse_lat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_lon = 'longitude'\n",
    "y_lon = d5_train[target_lon]\n",
    "\n",
    "# 2. Dividir os dados em treino e teste\n",
    "X_train, X_test, y_train_lon, y_test_lon = train_test_split(X, y_lon, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_lon = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=5,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Treinar o modelo\n",
    "xgb_lon.fit(X_train, y_train_lon,\n",
    "          eval_set=[(X_test, y_test_lon)],\n",
    "          verbose=False)\n",
    "\n",
    "# 4. Avaliar o modelo\n",
    "preds_lon = xgb_lon.predict(X_test)\n",
    "rmse_lon = np.sqrt(mean_squared_error(y_test_lon, preds_lon))\n",
    "print(f\"O RMSE para a previsão de Longitude é: {rmse_lon}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicando o modelo nos arquivos de teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eu não tinha visto que os arquivos eram pra ser enviados separados por hora, tinha pensado que era so por tipo de previsão por isso que tive que colocar esse código para dividir os dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d5_test_hr['datahora_dt'] = pd.to_datetime(d5_test_hr['datahora'], unit='ms')\n",
    "\n",
    "\n",
    "horario_de_corte = pd.Timestamp('2024-05-20 17:00:00')\n",
    "\n",
    "\n",
    "test_hr_1 = d5_test_hr[d5_test_hr['datahora_dt'] < horario_de_corte].copy()\n",
    "\n",
    "test_hr_2 = d5_test_hr[d5_test_hr['datahora_dt'] >= horario_de_corte].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "id1 = test_hr_1['indx']\n",
    "id2 = test_hr_2['indx']\n",
    "\n",
    "df_prev1 = test_hr_1[features]\n",
    "df_prev2 = test_hr_2[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1_lat = xgb_lat.predict(df_prev1)\n",
    "pred1_lon = xgb_lon.predict(df_prev1)\n",
    "\n",
    "pred2_lat = xgb_lat.predict(df_prev2)\n",
    "pred2_lon = xgb_lon.predict(df_prev2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#previsoes = [[i, float(la), float(lo)] for i, la, lo in zip(id1, pred1_lat, pred1_lon)]\n",
    "previsoes = [[i, float(la), float(lo)] for i, la, lo in zip(id2, pred2_lat, pred2_lon)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(previsoes, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando o arquivo `.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_para_submissao = {\n",
    "    \"aluno\": \"Luiz Guilherme de Andrade Pires\",\n",
    "    \"senha\": \"VascodaGama\",\n",
    "    \"datahora\": \"2024-05-20 17:00:00\", \n",
    "    \"previsoes\": previsoes\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'resposta.json'\n",
    "with open(file_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(dados_para_submissao, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando o modelo para encontrar a DataHora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_hr = [\n",
    "    'linha',\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "    'ordem_encoded',\n",
    "]\n",
    "\n",
    "target_hr = 'datahora'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = d5_train[features_hr]\n",
    "y_hr = d5_train[target_hr]\n",
    "\n",
    "X_train, X_test, y_train_hr, y_test_hr = train_test_split(X, y_hr, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_hr = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=5,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Treinar o modelo\n",
    "xgb_hr.fit(X_train, y_train_hr,\n",
    "          eval_set=[(X_test, y_test_hr)],\n",
    "          verbose=False)\n",
    "\n",
    "# 4. Avaliar o modelo\n",
    "preds_hr = xgb_hr.predict(X_test)\n",
    "rmse_hr = np.sqrt(mean_squared_error(y_test_hr, preds_hr))\n",
    "print(f\"O RMSE para a previsão de datahora é: {rmse_hr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicando o modelo no teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "d5_test_local1['ordem_encoded'] = label_encoder_ordem.fit_transform(d5_test_local1['ordem'])\n",
    "d5_test_local2['ordem_encoded'] = label_encoder_ordem.fit_transform(d5_test_local2['ordem'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "id1 = d5_test_local1['indx']\n",
    "id2 = d5_test_local2['indx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prev1_hr = d5_test_local1[features_hr]\n",
    "df_prev2_hr = d5_test_local2[features_hr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1_hr = xgb_hr.predict(df_prev1_hr)\n",
    "pred2_hr = xgb_hr.predict(df_prev2_hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#previsoes_hr = [[i, int(hr)] for i, hr in zip(id1, pred1_hr)]\n",
    "previsoes_hr = [[i, int(hr)] for i, hr in zip(id2, pred2_hr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(previsoes_hr, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando o arquivo `.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_para_submissao_hr = {\n",
    "    \"aluno\": \"Luiz Guilherme de Andrade Pires\",\n",
    "    \"senha\": \"VascodaGama\",\n",
    "    \"datahora\": \"2024-05-20 21:00:00\", \n",
    "    \"previsoes\": previsoes_hr\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'resposta.json'\n",
    "with open(file_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(dados_para_submissao_hr, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
